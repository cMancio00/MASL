{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelizzazione con [Numba](https://numba.pydata.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit, prange\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel = True)\n",
    "def replicate(sample_size:int,number_of_simulation:int,a:int,b:int,simulation_results:np.ndarray[np.float32])->np.float32:\n",
    "    for i in prange(number_of_simulation):\n",
    "        np.random.seed(111+i)\n",
    "        simulated_data = np.random.uniform(low=a,high=b,size=(sample_size,))\n",
    "        simulation_results[i] = simulated_data.mean()\n",
    "    return simulation_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questa piccola modifica abbiamo detto al compilatore che questa è una funzione che deve essere parallelizzata sulla CPU e se non riesce allora deve restituire un errore. Tutto questo è scritto nell'annotazione `@njit` che significa *non python just in time compiler*.\n",
    "La funzione `prange` di `numba` è l'equivalente di `range`, ma in parallelo.\n",
    "\n",
    "I cicli `for` così costruiti, ovvero con operazioni indipendenti, si possono parallelizzare senza problemi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media simulata: 1.499991423124075\n",
      "Media reale: 1.5\n"
     ]
    }
   ],
   "source": [
    "sample_size = 10000\n",
    "number_of_simulation = 100000\n",
    "a = 1\n",
    "b = 2\n",
    "m_U = (a + b) / 2\n",
    "sd_U = math.sqrt((b - a) ** 2 / 12)\n",
    "sd_m_U = m_U / math.sqrt(sd_U)\n",
    "\n",
    "simulation_results = np.empty(shape=(number_of_simulation,),dtype=np.float32)\n",
    "media_simulata = replicate(sample_size,number_of_simulation,a,b,simulation_results)\n",
    "\n",
    "print(\n",
    "    f\"Media simulata: {media_simulata}\\n\" +\n",
    "    f\"Media reale: {m_U}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adesso vediamo se la funzione parallela restituisce lo stesso valore della funzione non parallelizzata.\n",
    "Numba conserva la versione non parallelizzata nell'attributo `.py_func`.\n",
    "\n",
    "Per il testing utiliziamo il modulo `testing` di `numpy`.\n",
    "La funzione `testing.assert_almost_equal` restituisce un' eccezzione se i due valori in virgola mobile non sono uguali entro una certa tolleranza specificata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import testing\n",
    "\n",
    "testing.assert_almost_equal(\n",
    "    replicate(sample_size,number_of_simulation,a,b,simulation_results),\n",
    "    replicate.py_func(sample_size,number_of_simulation,a,b,simulation_results),\n",
    "    decimal=5\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scegliendo una tolleranza alla quinta cifra decimale, i due valori sono gli stessi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come ultimo test, vediamo che speed up abbiamo ottenuto parallelizzando questa simulazione.\n",
    "\n",
    "Utilizziamo il magic command `%timeit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540 ms ± 9.06 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "5.81 s ± 120 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit replicate(sample_size,number_of_simulation,a,b,simulation_results)\n",
    "%timeit replicate.py_func(sample_size,number_of_simulation,a,b,simulation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo ottenuto uno speed up di cerca 10 volte!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nel caso in cui si volesse parallelizzare sulla GPU si devono prendere accortezze differenti sia per le operazioni possibili (generare numeri casuali sulla GPU non è possibile in maniera semplice), e ai trasferimenti dei dati (la GPU ha la sua memoria e non una la RAM del processore, quindi i dati che utilizza vanno spostati nella VRAM e riposrtati in RAM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "1. [Numba documentation](https://numba.readthedocs.io/en/stable/user/jit.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvidia",
   "language": "python",
   "name": "nvidia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
